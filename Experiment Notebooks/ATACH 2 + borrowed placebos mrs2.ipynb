{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rulefit_uplift_forest import CausalRuleEnsembling\n",
    "from sklearn.model_selection import KFold\n",
    "from causalml.propensity import ElasticNetPropensityModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import miceforest as mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalml.match import create_table_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train our model on the ATACH2 + ERICH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('temp_data/imputed_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TREATMENT</th>\n",
       "      <th>DEMO_AGE</th>\n",
       "      <th>OUTCOME_mRS90</th>\n",
       "      <th>CT1_ICHVOL</th>\n",
       "      <th>CT1_IVHVOL</th>\n",
       "      <th>GCS_TTL</th>\n",
       "      <th>NIHSS_TTL</th>\n",
       "      <th>BP_S0</th>\n",
       "      <th>BP_D0</th>\n",
       "      <th>...</th>\n",
       "      <th>LB_BUN</th>\n",
       "      <th>LB_CREATINIE</th>\n",
       "      <th>RACE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>CT1_ICHSIDE</th>\n",
       "      <th>ICHLOC</th>\n",
       "      <th>source</th>\n",
       "      <th>group</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>764</td>\n",
       "      <td>1</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.30576</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.00</td>\n",
       "      <td>1.53</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thalamus</td>\n",
       "      <td>atach2</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>731</td>\n",
       "      <td>1</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.79725</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Basal Ganglia</td>\n",
       "      <td>atach2</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.78500</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.42</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>atach2</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.86619</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Basal Ganglia</td>\n",
       "      <td>atach2</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>527</td>\n",
       "      <td>1</td>\n",
       "      <td>79.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.65244</td>\n",
       "      <td>10.50645</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.60</td>\n",
       "      <td>0.75</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thalamus</td>\n",
       "      <td>atach2</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3701</th>\n",
       "      <td>946</td>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.77108</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.80</td>\n",
       "      <td>0.88</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thalamus</td>\n",
       "      <td>atach2</td>\n",
       "      <td>test</td>\n",
       "      <td>3701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3702</th>\n",
       "      <td>877</td>\n",
       "      <td>1</td>\n",
       "      <td>87.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.86191</td>\n",
       "      <td>5.68867</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Basal Ganglia</td>\n",
       "      <td>atach2</td>\n",
       "      <td>test</td>\n",
       "      <td>3702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3703</th>\n",
       "      <td>573</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.69418</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.86</td>\n",
       "      <td>1.11</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Basal Ganglia</td>\n",
       "      <td>atach2</td>\n",
       "      <td>test</td>\n",
       "      <td>3703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3704</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.06034</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1.60</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Basal Ganglia</td>\n",
       "      <td>atach2</td>\n",
       "      <td>test</td>\n",
       "      <td>3704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>79.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.87853</td>\n",
       "      <td>16.70670</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.70</td>\n",
       "      <td>1.09</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thalamus</td>\n",
       "      <td>atach2</td>\n",
       "      <td>test</td>\n",
       "      <td>3705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3706 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  TREATMENT  DEMO_AGE  OUTCOME_mRS90  CT1_ICHVOL  CT1_IVHVOL  \\\n",
       "0            764          1      90.0            2.0     0.30576     0.00000   \n",
       "1            731          1      63.0            0.0     7.79725     0.00000   \n",
       "2            210          1      51.0            0.0     5.78500     0.00000   \n",
       "3            142          1      48.0            5.0    26.86619     0.00000   \n",
       "4            527          1      79.0            4.0     7.65244    10.50645   \n",
       "...          ...        ...       ...            ...         ...         ...   \n",
       "3701         946          0      61.0            4.0     6.77108     0.00000   \n",
       "3702         877          1      87.0            5.0    16.86191     5.68867   \n",
       "3703         573          0      44.0            3.0    24.69418     0.00000   \n",
       "3704         886          0      54.0            2.0     7.06034     0.00000   \n",
       "3705         463          1      79.0            4.0     7.87853    16.70670   \n",
       "\n",
       "      GCS_TTL  NIHSS_TTL  BP_S0  BP_D0  ...  LB_BUN  LB_CREATINIE   RACE  \\\n",
       "0        15.0        2.0  194.0   81.0  ...   24.00          1.53  White   \n",
       "1        15.0        3.0  163.0   88.0  ...   10.00          0.96  Asian   \n",
       "2        15.0        9.0  180.0   80.0  ...   17.42          1.01  Asian   \n",
       "3         9.0       24.0  144.0   88.0  ...   13.00          0.84  Black   \n",
       "4        12.0       15.0  179.0   74.0  ...   15.60          0.75  White   \n",
       "...       ...        ...    ...    ...  ...     ...           ...    ...   \n",
       "3701     15.0       17.0  191.0  105.0  ...   15.80          0.88  Asian   \n",
       "3702      9.0       15.0  179.0   69.0  ...   15.00          1.01  Asian   \n",
       "3703     12.0        8.0  210.0  120.0  ...   21.86          1.11  Asian   \n",
       "3704     15.0        3.0  209.0  106.0  ...   19.00          1.60  Black   \n",
       "3705     14.0       10.0  178.0  149.0  ...   17.70          1.09  Asian   \n",
       "\n",
       "      GENDER     ETHNICITY  CT1_ICHSIDE         ICHLOC  source  group  index  \n",
       "0       Male  Non-Hispanic          0.0       Thalamus  atach2  train      0  \n",
       "1       Male  Non-Hispanic          0.0  Basal Ganglia  atach2  train      1  \n",
       "2       Male  Non-Hispanic          1.0          Other  atach2  train      2  \n",
       "3     Female  Non-Hispanic          0.0  Basal Ganglia  atach2  train      3  \n",
       "4     Female  Non-Hispanic          0.0       Thalamus  atach2  train      4  \n",
       "...      ...           ...          ...            ...     ...    ...    ...  \n",
       "3701  Female  Non-Hispanic          1.0       Thalamus  atach2   test   3701  \n",
       "3702    Male  Non-Hispanic          1.0  Basal Ganglia  atach2   test   3702  \n",
       "3703    Male  Non-Hispanic          1.0  Basal Ganglia  atach2   test   3703  \n",
       "3704    Male  Non-Hispanic          1.0  Basal Ganglia  atach2   test   3704  \n",
       "3705    Male  Non-Hispanic          0.0       Thalamus  atach2   test   3705  \n",
       "\n",
       "[3706 rows x 42 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_var(df):\n",
    "    df['age'] = (df['DEMO_AGE'] - np.mean(df['DEMO_AGE'])) / np.std(df['DEMO_AGE'])\n",
    "    df['ich_vol'] = np.log(df['CT1_ICHVOL'] + 1)\n",
    "    df['ivh_vol'] = np.log(df['CT1_IVHVOL'] + 1)\n",
    "    df['gcs'] = (df['GCS_TTL'] - np.mean(df['GCS_TTL'])) / np.std(df['GCS_TTL'])\n",
    "    df['nihss'] = np.log(df['NIHSS_TTL'] + 1)\n",
    "    df['sbp'] = (df['BP_S0'] - np.mean(df['BP_S0'])) / np.std(df['BP_S0'])\n",
    "    df['dbp'] = (df['BP_D0'] - np.mean(df['BP_D0'])) / np.std(df['BP_D0'])\n",
    "    df['PP'] = df['BP_S0'] - df['BP_D0']\n",
    "    df['MAP'] = df['BP_S0']/3 + df['BP_D0']*2/3\n",
    "    df['pp'] = (df['PP'] -np.mean(df['PP'])) / np.std(df['PP'])\n",
    "    df['map'] = (df['MAP'] - np.mean(df['MAP']))/np.std(df['MAP'])\n",
    "    \n",
    "    df['pc'] = (df['LB_PC'] - np.mean(df['LB_PC'])) / np.std(df['LB_PC'])\n",
    "    df['glucose'] = (df['LB_GLUCOSE'] - np.mean(df['LB_GLUCOSE'])) / np.std(df['LB_GLUCOSE'])\n",
    "    df['sodium'] = (df['LB_SODIUM'] - np.mean(df['LB_SODIUM'])) / np.std(df['LB_SODIUM'])\n",
    "    df['potassium'] = (df['LB_POTASSIUM'] - np.mean(df['LB_POTASSIUM'])) / np.std(df['LB_POTASSIUM'])\n",
    "    df['chloride'] = (df['LB_CHLORIDE'] - np.mean(df['LB_CHLORIDE'])) / np.std(df['LB_CHLORIDE'])\n",
    "    df['cd'] = (df['LB_CD'] - np.mean(df['LB_CD'])) / np.std(df['LB_CD'])\n",
    "    df['bun'] = (df['LB_BUN'] - np.mean(df['LB_BUN'])) / np.std(df['LB_BUN'])\n",
    "    df['hemoglobin'] = (df['LB_HEMOGLOBIN'] - np.mean(df['LB_HEMOGLOBIN'])) / np.std(df['LB_HEMOGLOBIN'])\n",
    "    df['hematocrit'] = (df['LB_HEMATOCRIT'] - np.mean(df['LB_HEMATOCRIT'])) / np.std(df['LB_HEMATOCRIT'])\n",
    "    df['wbc'] = (df['LB_WBC'] - np.mean(df['LB_WBC'])) / np.std(df['LB_WBC'])\n",
    "    df['creatinie'] = (df['LB_CREATINIE'] - np.mean(df['LB_CREATINIE'])) / np.std(df['LB_CREATINIE'])\n",
    "    df['aptt'] = (df['LB_APTT'] - np.mean(df['LB_APTT'])) / np.std(df['LB_APTT'])\n",
    "    df['inr'] = (df['LB_INR'] - np.mean(df['LB_INR'])) / np.std(df['LB_INR'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_transform_var(df, train):\n",
    "    # Using the training data to \n",
    "    df['age'] = (df['DEMO_AGE'] - np.mean(train['DEMO_AGE'])) / np.std(train['DEMO_AGE'])\n",
    "    df['ich_vol'] = np.log(df['CT1_ICHVOL'] + 1)\n",
    "    df['ivh_vol'] = np.log(df['CT1_IVHVOL'] + 1)\n",
    "    df['gcs'] = (df['GCS_TTL'] - np.mean(train['GCS_TTL'])) / np.std(train['GCS_TTL'])\n",
    "    df['nihss'] = np.log(df['NIHSS_TTL'] + 1)\n",
    "    df['sbp'] = (df['BP_S0'] - np.mean(train['BP_S0'])) / np.std(train['BP_S0'])\n",
    "    df['dbp'] = (df['BP_D0'] - np.mean(train['BP_D0'])) / np.std(train['BP_D0'])\n",
    "    \n",
    "    df['PP'] = df['BP_S0'] - df['BP_D0']\n",
    "    df['MAP'] = df['BP_S0']/3 + df['BP_D0']*2/3\n",
    "    df['pp'] = (df['PP'] -np.mean(train['PP'])) / np.std(train['PP'])\n",
    "    df['map'] = (df['MAP'] - np.mean(train['MAP']))/np.std(train['MAP'])\n",
    "    \n",
    "    df['pc'] = (df['LB_PC'] - np.mean(train['LB_PC'])) / np.std(train['LB_PC'])\n",
    "    df['glucose'] = (df['LB_GLUCOSE'] - np.mean(train['LB_GLUCOSE'])) / np.std(train['LB_GLUCOSE'])\n",
    "    df['sodium'] = (df['LB_SODIUM'] - np.mean(train['LB_SODIUM'])) / np.std(train['LB_SODIUM'])\n",
    "    df['potassium'] = (df['LB_POTASSIUM'] - np.mean(train['LB_POTASSIUM'])) / np.std(train['LB_POTASSIUM'])\n",
    "    df['chloride'] = (df['LB_CHLORIDE'] - np.mean(train['LB_CHLORIDE'])) / np.std(train['LB_CHLORIDE'])\n",
    "    df['cd'] = (df['LB_CD'] - np.mean(train['LB_CD'])) / np.std(train['LB_CD'])\n",
    "    df['bun'] = (df['LB_BUN'] - np.mean(train['LB_BUN'])) / np.std(train['LB_BUN'])\n",
    "    df['hemoglobin'] = (df['LB_HEMOGLOBIN'] - np.mean(train['LB_HEMOGLOBIN'])) / np.std(train['LB_HEMOGLOBIN'])\n",
    "    df['hematocrit'] = (df['LB_HEMATOCRIT'] - np.mean(train['LB_HEMATOCRIT'])) / np.std(train['LB_HEMATOCRIT'])\n",
    "    df['wbc'] = (df['LB_WBC'] - np.mean(train['LB_WBC'])) / np.std(train['LB_WBC'])\n",
    "    df['creatinie'] = (df['LB_CREATINIE'] - np.mean(train['LB_CREATINIE'])) / np.std(train['LB_CREATINIE'])\n",
    "    df['aptt'] = (df['LB_APTT'] - np.mean(train['LB_APTT'])) / np.std(train['LB_APTT'])\n",
    "    df['inr'] = (df['LB_INR'] - np.mean(train['LB_INR'])) / np.std(train['LB_INR'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propensity score matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalml.match import NearestNeighborMatch, create_table_one\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_treatment_var = ['age', 'ich_vol', 'ivh_vol', 'gcs', 'nihss', 'sbp', 'dbp', 'pp', 'map', \n",
    "                     'RACE_Asian', 'RACE_Black', 'RACE_Other', 'RACE_White', 'GENDER_Male', 'GENDER_Female',\n",
    "                     'ETHNICITY_Hispanic', 'ETHNICITY_Non-Hispanic',\n",
    "                     \n",
    "                     'HIS_HYPERTENSION', 'HIS_HYPERLIPIDEMIA', 'HIS_DM2',\n",
    "                     'HIS_DM1', 'HIS_HF', 'HIS_AF', 'HIS_PTCA', 'HIS_PV','HIS_MYOCARDIAL', \n",
    "                     'HIS_ANTIDIABETIC', 'HIS_ANTIHYPERTENSIVES',\n",
    "                     \n",
    "                     'CT1_ICHSIDE','ICHLOC_Basal Ganglia','ICHLOC_Lobar', 'ICHLOC_Other', 'ICHLOC_Thalamus', \n",
    "                     \n",
    "                     'wbc', 'hemoglobin','hematocrit', 'pc', 'aptt', 'inr', 'glucose',\n",
    "                     'sodium', 'potassium', 'chloride', 'cd', 'bun','creatinie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = df['source']\n",
    "group = df['group']\n",
    "df_new = df.copy()\n",
    "df_new.drop(columns=['source', 'group'], inplace=True)\n",
    "df_new = pd.get_dummies(df_new)\n",
    "df_new['source'] = source\n",
    "df_new['group'] = group\n",
    "df_new['index'] = df['index']\n",
    "trial = df_new[df_new['source'] == 'atach2'].copy()\n",
    "trial_train = trial[trial['group'] == 'train'].copy()\n",
    "trial_test = trial[trial['group'] == 'test'].copy()\n",
    "trial_train = transform_var(trial_train)\n",
    "trial_test = test_transform_var(trial_test, trial_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_new[df_new['group'] == 'train'].copy()\n",
    "df_train = transform_var(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3506"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26606956521739134"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_all = create_table_one(df_train, 'TREATMENT',pre_treatment_var)\n",
    "a = 0\n",
    "b = 0\n",
    "# Calculate average smd on ERICH + ATACH2\n",
    "for i in range(len(eval_all['SMD'])):\n",
    "    if (eval_all['SMD'][i] !='') & ~(pd.isna(eval_all['SMD'][i])):\n",
    "        a += abs(eval_all['SMD'][i])\n",
    "        b += 1\n",
    "a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.918327\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df_train[pre_treatment_var])\n",
    "y = np.array(df_train['TREATMENT'])\n",
    "pm = LogisticRegression(penalty='none', max_iter=3000)\n",
    "pm.fit(X, y)\n",
    "clip_bounds = (1e-3, 1-1e-3)\n",
    "score_lgr = np.clip(pm.predict_proba(X)[:, 1], *clip_bounds)\n",
    "print('AUC score: {:.6f}'.format(auc(y, score_lgr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['score'] = score_lgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_train[~((df_train['TREATMENT'] == 0) & (df_train['source'] == 'atach2'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_temp.reset_index(inplace=True, drop=True)\n",
    "psm = NearestNeighborMatch(caliper=0.2, replace=False, ratio=1, random_state=11)\n",
    "matched = psm.match(data=df_temp, treatment_col='TREATMENT',score_cols=['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_erich = matched[matched['source'] == 'erich']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matched_erich)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'TREATMENT', 'DEMO_AGE', 'OUTCOME_mRS90', 'CT1_ICHVOL',\n",
       "       'CT1_IVHVOL', 'GCS_TTL', 'NIHSS_TTL', 'BP_S0', 'BP_D0',\n",
       "       'HIS_HYPERTENSION', 'HIS_HYPERLIPIDEMIA', 'HIS_DM1', 'HIS_DM2',\n",
       "       'HIS_HF', 'HIS_AF', 'HIS_PTCA', 'HIS_PV', 'HIS_MYOCARDIAL',\n",
       "       'HIS_ANTIDIABETIC', 'HIS_ANTIHYPERTENSIVES', 'LB_WBC', 'LB_HEMOGLOBIN',\n",
       "       'LB_HEMATOCRIT', 'LB_PC', 'LB_APTT', 'LB_INR', 'LB_GLUCOSE',\n",
       "       'LB_SODIUM', 'LB_POTASSIUM', 'LB_CHLORIDE', 'LB_CD', 'LB_BUN',\n",
       "       'LB_CREATINIE', 'CT1_ICHSIDE', 'index', 'RACE_Asian', 'RACE_Black',\n",
       "       'RACE_Other', 'RACE_White', 'GENDER_Female', 'GENDER_Male',\n",
       "       'ETHNICITY_Hispanic', 'ETHNICITY_Non-Hispanic', 'ICHLOC_Basal Ganglia',\n",
       "       'ICHLOC_Lobar', 'ICHLOC_Other', 'ICHLOC_Thalamus', 'source', 'group',\n",
       "       'age', 'ich_vol', 'ivh_vol', 'gcs', 'nihss', 'sbp', 'dbp', 'PP', 'MAP',\n",
       "       'pp', 'map', 'pc', 'glucose', 'sodium', 'potassium', 'chloride', 'cd',\n",
       "       'bun', 'hemoglobin', 'hematocrit', 'wbc', 'creatinie', 'aptt', 'inr',\n",
       "       'score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_erich.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.653936\n"
     ]
    }
   ],
   "source": [
    "merge = pd.concat([trial_train, matched_erich])\n",
    "pre_treatment_var = ['age', 'ich_vol', 'ivh_vol', 'gcs', 'nihss', 'sbp', 'dbp', 'pp', 'map', \n",
    "                     'RACE_Asian', 'RACE_Black', 'RACE_Other', 'RACE_White', 'GENDER_Male', 'GENDER_Female',\n",
    "                     'ETHNICITY_Hispanic', 'ETHNICITY_Non-Hispanic',\n",
    "                     \n",
    "                     'HIS_HYPERTENSION', 'HIS_HYPERLIPIDEMIA', 'HIS_DM2',\n",
    "                     'HIS_DM1', 'HIS_HF', 'HIS_AF', 'HIS_PTCA', 'HIS_PV','HIS_MYOCARDIAL', \n",
    "                     'HIS_ANTIDIABETIC', 'HIS_ANTIHYPERTENSIVES',\n",
    "                     \n",
    "                     'CT1_ICHSIDE','ICHLOC_Basal Ganglia', 'ICHLOC_Lobar', 'ICHLOC_Thalamus', 'ICHLOC_Other', \n",
    "                     \n",
    "                     'wbc', 'hemoglobin','hematocrit', 'pc', 'aptt', 'inr', 'glucose',\n",
    "                     'sodium', 'potassium', 'chloride', 'cd', 'bun','creatinie']\n",
    "X = np.array(merge[pre_treatment_var])\n",
    "y = np.array(merge['TREATMENT'])\n",
    "pm_lgr = LogisticRegression(penalty='none', max_iter=3000)\n",
    "pm_lgr.fit(X, y)\n",
    "clip_bounds = (1e-3, 1-1e-3)\n",
    "score_lgr = np.clip(pm_lgr.predict_proba(X)[:, 1], *clip_bounds)\n",
    "print('AUC score: {:.6f}'.format(auc(y, score_lgr)))\n",
    "merge['score'] = score_lgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(934, 3506)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merge), len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06047826086956524"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_merge = create_table_one(merge, 'TREATMENT',pre_treatment_var)\n",
    "a = 0\n",
    "b = 0\n",
    "# Calculate average smd on ERICH + ATACH2\n",
    "for i in range(len(eval_merge['SMD'])):\n",
    "    if (eval_merge['SMD'][i] !='') & ~(pd.isna(eval_merge['SMD'][i])):\n",
    "        a += abs(eval_merge['SMD'][i])\n",
    "        b += 1\n",
    "a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matched_erich.to_csv('temp_data/matched_erich.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04847826086956521"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average smd on ERICH + ATACH2\n",
    "eval_trial = create_table_one(trial_train, 'TREATMENT',pre_treatment_var)\n",
    "a = 0\n",
    "b = 0\n",
    "for i in range(len(eval_trial['SMD'])):\n",
    "    if (eval_trial['SMD'][i] !='') & ~(pd.isna(eval_trial['SMD'][i])):\n",
    "        a += abs(eval_trial['SMD'][i])\n",
    "        b += 1\n",
    "a/b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model\n",
    "selected model from CV:\n",
    "\n",
    "tree:\n",
    "- max_depth = 3\n",
    "- n_reg = 5\n",
    "- n_samples = 80\n",
    "- min_treatment_samples = 30\n",
    "\n",
    "Ensemble:\n",
    "- max_depth = 3\n",
    "- n_reg = 5\n",
    "- n_samples = 80\n",
    "- min_treatment_samples = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results (multiple seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([trial_train, matched_erich])\n",
    "train_X = np.array(train[pre_treatment_var])\n",
    "test_X = np.array(trial_test[pre_treatment_var])\n",
    "train_treatment=(train['TREATMENT']!=0).astype(int).values\n",
    "test_treatment=(trial_test['TREATMENT']!=0).astype(int).values\n",
    "y_train = (train['OUTCOME_mRS90']).values\n",
    "y_test = (trial_test['OUTCOME_mRS90']).values\n",
    "y_bin_train = np.array([0] * len(y_train))\n",
    "y_bin_train[np.where(y_train <= 3)] = 1\n",
    "y_bin_test = np.array([0] * len(y_test))\n",
    "y_bin_test[np.where(y_test <= 3)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(934, 46)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_train = ['control'] * len(train_treatment)\n",
    "for i in range(len(train_treatment)):\n",
    "    if train_treatment[i] == 1:\n",
    "        treatment_train[i] = 'treatment'\n",
    "treatment_train = np.array(treatment_train)\n",
    "treatment_test = ['control'] * len(test_treatment)\n",
    "for i in range(len(test_treatment)):\n",
    "    if test_treatment[i] == 1:\n",
    "        treatment_test[i] = 'treatment'\n",
    "treatment_test = np.array(treatment_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 46), (200,), (200,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape, y_bin_test.shape, treatment_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050482793298807054"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uplift_forest_customed import UpliftTreeNew\n",
    "model_tree = UpliftTreeNew(n_reg=5, min_samples_leaf = 80, min_samples_treatment = 30, random_state=100, control_name='control')\n",
    "model_tree.fit(train_X, treatment_train, y_bin_train)\n",
    "model_tree.eval_qini(test_X, y_bin_test, test_treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_rules = model_tree.get_rules()\n",
    "len(tree_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed round: 0 Qini: -0.01304955329039506\n",
      "Seed round: 1 Qini: -0.008396843297814755\n",
      "Seed round: 2 Qini: 0.004766745345914925\n",
      "Seed round: 3 Qini: 0.034404258749558915\n",
      "Seed round: 4 Qini: 0.005657889592928664\n",
      "Seed round: 5 Qini: 0.009493979075801042\n",
      "Seed round: 6 Qini: -0.007678108844869361\n",
      "Seed round: 7 Qini: 0.021581647474610985\n",
      "Seed round: 8 Qini: -0.014091666080206556\n",
      "Seed round: 9 Qini: 0.047835559436617985\n",
      "Seed round: 10 Qini: -0.016933942326576513\n",
      "Seed round: 11 Qini: 0.016723279707115193\n",
      "Seed round: 12 Qini: 0.010701978820323785\n",
      "Seed round: 13 Qini: 0.023588723645631544\n",
      "Seed round: 14 Qini: 0.049204094562025055\n",
      "Seed round: 15 Qini: 0.03995023626569345\n",
      "Seed round: 16 Qini: -0.018803611142520705\n",
      "Seed round: 17 Qini: 0.019813678224592294\n",
      "Seed round: 18 Qini: 0.019159188657065788\n",
      "Seed round: 19 Qini: 7.575387859469125e-05\n",
      "Seed round: 20 Qini: 0.03156256366835131\n",
      "Seed round: 21 Qini: 0.00833355706044907\n",
      "Seed round: 22 Qini: -0.0032294392779179905\n",
      "Seed round: 23 Qini: 0.0004223339118331749\n",
      "Seed round: 24 Qini: 0.04181127057920583\n",
      "Seed round: 25 Qini: -0.007508910225007168\n",
      "Seed round: 26 Qini: 0.018788535733937226\n",
      "Seed round: 27 Qini: -0.02419160310034008\n",
      "Seed round: 28 Qini: 0.020725535616556705\n",
      "Seed round: 29 Qini: 0.011764311687627923\n"
     ]
    }
   ],
   "source": [
    "qini_max = -1\n",
    "res = {'res_tree':[], 'res_lasso':[]}\n",
    "for seed in range(0, 30):\n",
    "    model_temp = CausalRuleEnsembling(\n",
    "         tree_depth = 3, \n",
    "         tree_eval_func = 'KL', \n",
    "         n_reg=5, \n",
    "         n_estimator = 100,           \n",
    "         min_samples_leaf =80, \n",
    "         min_samples_treatment = 30, \n",
    "         model_type='rl', \n",
    "         lin_standardise=False,\n",
    "         random_state = seed)\n",
    "    model_temp.fit(train_X, treatment_train, y_bin_train, pre_treatment_var)\n",
    "    a, b = model_temp.eval_qini(test_X, y_bin_test, test_treatment)\n",
    "    \n",
    "    \n",
    "    res['res_tree'].append(a)\n",
    "    res['res_lasso'].append(b)\n",
    "    print('Seed round:', seed, 'Qini:', b)\n",
    "    if b > qini_max:\n",
    "        qini_max = b\n",
    "        final_model = model_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.009600142665959875, 0.010749381470292913)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(res['res_tree']),np.mean(res['res_lasso'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.020029408639315877, 0.01989059784251751)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(res['res_tree']),np.std(res['res_lasso'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/AE_tree_mrs2.txt', 'w') as filehandle:\n",
    "    for listitem in res['res_tree']:\n",
    "        filehandle.write(f'{listitem}\\n')\n",
    "\n",
    "with open('results/AE_ensemble_mrs2.txt', 'w') as filehandle:\n",
    "    for listitem in res['res_lasso']:\n",
    "        filehandle.write(f'{listitem}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = final_model.get_rules()\n",
    "rules = rules[rules['type']=='rule']\n",
    "rules_ = rules[(rules['coef'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213, 171)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rules), len(rules_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
