{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac782c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rulefit_uplift_forest import CausalRuleEnsembling\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sdv\n",
    "from sdv.sampling import Condition\n",
    "import torch\n",
    "import pickle\n",
    "from causalml.match import NearestNeighborMatch, create_table_one\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn import preprocessing\n",
    "from causalml.propensity import ElasticNetPropensityModel\n",
    "from sdmetrics.reports.single_table import QualityReport\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e00c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'temp_data/'\n",
    "df = pd.read_csv(directory + 'imputed_all.csv')\n",
    "df.drop(columns=['Unnamed: 0'], inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b25859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pd.read_csv(directory + 'matched_erich.csv')\n",
    "obs.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'score', 'source', 'group'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97979621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 71)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e82709ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TREATMENT', 'DEMO_AGE', 'OUTCOME_mRS90', 'CT1_ICHVOL', 'CT1_IVHVOL',\n",
       "       'GCS_TTL', 'NIHSS_TTL', 'BP_S0', 'BP_D0', 'HIS_HYPERTENSION',\n",
       "       'HIS_HYPERLIPIDEMIA', 'HIS_DM1', 'HIS_DM2', 'HIS_HF', 'HIS_AF',\n",
       "       'HIS_PTCA', 'HIS_PV', 'HIS_MYOCARDIAL', 'HIS_ANTIDIABETIC',\n",
       "       'HIS_ANTIHYPERTENSIVES', 'LB_WBC', 'LB_HEMOGLOBIN', 'LB_HEMATOCRIT',\n",
       "       'LB_PC', 'LB_APTT', 'LB_INR', 'LB_GLUCOSE', 'LB_SODIUM', 'LB_POTASSIUM',\n",
       "       'LB_CHLORIDE', 'LB_CD', 'LB_BUN', 'LB_CREATINIE', 'CT1_ICHSIDE',\n",
       "       'index', 'RACE_Asian', 'RACE_Black', 'RACE_Other', 'RACE_White',\n",
       "       'GENDER_Female', 'GENDER_Male', 'ETHNICITY_Hispanic',\n",
       "       'ETHNICITY_Non-Hispanic', 'ICHLOC_Basal Ganglia', 'ICHLOC_Lobar',\n",
       "       'ICHLOC_Other', 'ICHLOC_Thalamus', 'age', 'ich_vol', 'ivh_vol', 'gcs',\n",
       "       'nihss', 'sbp', 'dbp', 'PP', 'MAP', 'pp', 'map', 'pc', 'glucose',\n",
       "       'sodium', 'potassium', 'chloride', 'cd', 'bun', 'hemoglobin',\n",
       "       'hematocrit', 'wbc', 'creatinie', 'aptt', 'inr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12a66e2",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afd98304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_var(df):\n",
    "    df['age'] = (df['DEMO_AGE'] - np.mean(df['DEMO_AGE'])) / np.std(df['DEMO_AGE'])\n",
    "    df['ich_vol'] = np.log(df['CT1_ICHVOL'] + 1)\n",
    "    df['ivh_vol'] = np.log(df['CT1_IVHVOL'] + 1)\n",
    "    df['gcs'] = (df['GCS_TTL'] - np.mean(df['GCS_TTL'])) / np.std(df['GCS_TTL'])\n",
    "    df['nihss'] = np.log(df['NIHSS_TTL'] + 1)\n",
    "    df['sbp'] = (df['BP_S0'] - np.mean(df['BP_S0'])) / np.std(df['BP_S0'])\n",
    "    df['dbp'] = (df['BP_D0'] - np.mean(df['BP_D0'])) / np.std(df['BP_D0'])\n",
    "    df['PP'] = df['BP_S0'] - df['BP_D0']\n",
    "    df['MAP'] = df['BP_S0']/3 + df['BP_D0']*2/3\n",
    "    df['pp'] = (df['PP'] -np.mean(df['PP'])) / np.std(df['PP'])\n",
    "    df['map'] = (df['MAP'] - np.mean(df['MAP']))/np.std(df['MAP'])\n",
    "    \n",
    "    df['pc'] = (df['LB_PC'] - np.mean(df['LB_PC'])) / np.std(df['LB_PC'])\n",
    "    df['glucose'] = (df['LB_GLUCOSE'] - np.mean(df['LB_GLUCOSE'])) / np.std(df['LB_GLUCOSE'])\n",
    "    df['sodium'] = (df['LB_SODIUM'] - np.mean(df['LB_SODIUM'])) / np.std(df['LB_SODIUM'])\n",
    "    df['potassium'] = (df['LB_POTASSIUM'] - np.mean(df['LB_POTASSIUM'])) / np.std(df['LB_POTASSIUM'])\n",
    "    df['chloride'] = (df['LB_CHLORIDE'] - np.mean(df['LB_CHLORIDE'])) / np.std(df['LB_CHLORIDE'])\n",
    "    df['cd'] = (df['LB_CD'] - np.mean(df['LB_CD'])) / np.std(df['LB_CD'])\n",
    "    df['bun'] = (df['LB_BUN'] - np.mean(df['LB_BUN'])) / np.std(df['LB_BUN'])\n",
    "    df['hemoglobin'] = (df['LB_HEMOGLOBIN'] - np.mean(df['LB_HEMOGLOBIN'])) / np.std(df['LB_HEMOGLOBIN'])\n",
    "    df['hematocrit'] = (df['LB_HEMATOCRIT'] - np.mean(df['LB_HEMATOCRIT'])) / np.std(df['LB_HEMATOCRIT'])\n",
    "    df['wbc'] = (df['LB_WBC'] - np.mean(df['LB_WBC'])) / np.std(df['LB_WBC'])\n",
    "    df['creatinie'] = (df['LB_CREATINIE'] - np.mean(df['LB_CREATINIE'])) / np.std(df['LB_CREATINIE'])\n",
    "    df['aptt'] = (df['LB_APTT'] - np.mean(df['LB_APTT'])) / np.std(df['LB_APTT'])\n",
    "    df['inr'] = (df['LB_INR'] - np.mean(df['LB_INR'])) / np.std(df['LB_INR'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "416c31ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_transform_var(df, train):\n",
    "    # Using the training data to \n",
    "    df['age'] = (df['DEMO_AGE'] - np.mean(train['DEMO_AGE'])) / np.std(train['DEMO_AGE'])\n",
    "    df['ich_vol'] = np.log(df['CT1_ICHVOL'] + 1)\n",
    "    df['ivh_vol'] = np.log(df['CT1_IVHVOL'] + 1)\n",
    "    df['gcs'] = (df['GCS_TTL'] - np.mean(train['GCS_TTL'])) / np.std(train['GCS_TTL'])\n",
    "    df['nihss'] = np.log(df['NIHSS_TTL'] + 1)\n",
    "    df['sbp'] = (df['BP_S0'] - np.mean(train['BP_S0'])) / np.std(train['BP_S0'])\n",
    "    df['dbp'] = (df['BP_D0'] - np.mean(train['BP_D0'])) / np.std(train['BP_D0'])\n",
    "    \n",
    "    df['PP'] = df['BP_S0'] - df['BP_D0']\n",
    "    df['MAP'] = df['BP_S0']/3 + df['BP_D0']*2/3\n",
    "    df['pp'] = (df['PP'] -np.mean(train['PP'])) / np.std(train['PP'])\n",
    "    df['map'] = (df['MAP'] - np.mean(train['MAP']))/np.std(train['MAP'])\n",
    "    \n",
    "    df['pc'] = (df['LB_PC'] - np.mean(train['LB_PC'])) / np.std(train['LB_PC'])\n",
    "    df['glucose'] = (df['LB_GLUCOSE'] - np.mean(train['LB_GLUCOSE'])) / np.std(train['LB_GLUCOSE'])\n",
    "    df['sodium'] = (df['LB_SODIUM'] - np.mean(train['LB_SODIUM'])) / np.std(train['LB_SODIUM'])\n",
    "    df['potassium'] = (df['LB_POTASSIUM'] - np.mean(train['LB_POTASSIUM'])) / np.std(train['LB_POTASSIUM'])\n",
    "    df['chloride'] = (df['LB_CHLORIDE'] - np.mean(train['LB_CHLORIDE'])) / np.std(train['LB_CHLORIDE'])\n",
    "    df['cd'] = (df['LB_CD'] - np.mean(train['LB_CD'])) / np.std(train['LB_CD'])\n",
    "    df['bun'] = (df['LB_BUN'] - np.mean(train['LB_BUN'])) / np.std(train['LB_BUN'])\n",
    "    df['hemoglobin'] = (df['LB_HEMOGLOBIN'] - np.mean(train['LB_HEMOGLOBIN'])) / np.std(train['LB_HEMOGLOBIN'])\n",
    "    df['hematocrit'] = (df['LB_HEMATOCRIT'] - np.mean(train['LB_HEMATOCRIT'])) / np.std(train['LB_HEMATOCRIT'])\n",
    "    df['wbc'] = (df['LB_WBC'] - np.mean(train['LB_WBC'])) / np.std(train['LB_WBC'])\n",
    "    df['creatinie'] = (df['LB_CREATINIE'] - np.mean(train['LB_CREATINIE'])) / np.std(train['LB_CREATINIE'])\n",
    "    df['aptt'] = (df['LB_APTT'] - np.mean(train['LB_APTT'])) / np.std(train['LB_APTT'])\n",
    "    df['inr'] = (df['LB_INR'] - np.mean(train['LB_INR'])) / np.std(train['LB_INR'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39b78740",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_treatment_var = ['age', 'ich_vol', 'ivh_vol', 'gcs', 'nihss', 'sbp', 'dbp', 'pp', 'map', \n",
    "                     'RACE_Asian', 'RACE_Black', 'RACE_Other', 'RACE_White', 'GENDER_Male', 'GENDER_Female',\n",
    "                     'ETHNICITY_Hispanic','ETHNICITY_Non-Hispanic',\n",
    "                     \n",
    "                     'HIS_HYPERTENSION', 'HIS_HYPERLIPIDEMIA', 'HIS_DM2',\n",
    "                     'HIS_DM1', 'HIS_HF', 'HIS_AF', 'HIS_PTCA', 'HIS_PV','HIS_MYOCARDIAL', \n",
    "                     'HIS_ANTIDIABETIC', 'HIS_ANTIHYPERTENSIVES',\n",
    "                     \n",
    "                     'CT1_ICHSIDE','ICHLOC_Basal Ganglia', 'ICHLOC_Lobar', 'ICHLOC_Thalamus', 'ICHLOC_Other',\n",
    "                     \n",
    "                     'wbc', 'hemoglobin','hematocrit', 'pc', 'aptt', 'inr', 'glucose',\n",
    "                     'sodium', 'potassium', 'chloride', 'cd', 'bun','creatinie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "641d8dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3506"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sdv.tabular import TVAE\n",
    "trial_temp = df[(df['source'] == 'atach2')&(df['group']=='train')].copy()\n",
    "trial_temp.reset_index(inplace=True, drop=True)\n",
    "erich_temp = df[df['source'] == 'erich'].copy()\n",
    "df_train_syn = pd.concat([trial_temp, erich_temp], axis=0)\n",
    "len(df_train_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5865b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_syn.drop(columns=['group', 'index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f8f9225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED_VALUE = 10\n",
    "# np.random.seed(SEED_VALUE)\n",
    "# torch.manual_seed(SEED_VALUE)\n",
    "# tvae_model = TVAE(cuda=True)\n",
    "# tvae_model.fit(df_train_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "505054f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tvae_model.save('temp_data/TVAE_comb_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86676f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvae_model = TVAE.load('temp_data/TVAE_comb_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a4b8e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|██████████| 500/500 [00:03<00:00, 162.51it/s]\n",
      "Sampling conditions: 100%|██████████| 500/500 [00:00<00:00, 941.04it/s] \n"
     ]
    }
   ],
   "source": [
    "SEED_VALUE = 20\n",
    "np.random.seed(SEED_VALUE)\n",
    "torch.manual_seed(SEED_VALUE)\n",
    "cond1 = Condition({'TREATMENT':1}, 500)\n",
    "cond2 = Condition({'TREATMENT':0}, 500)\n",
    "\n",
    "new_data_t2 = tvae_model.sample_conditions(conditions=[cond1])\n",
    "new_data_c2 = tvae_model.sample_conditions(conditions=[cond2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3042bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn2 = pd.concat([new_data_t2, new_data_c2])\n",
    "syn2.reset_index(drop=True, inplace=True)\n",
    "syn2.to_csv('temp_data/tvae_syn_new.csv')\n",
    "syn2.drop(columns=['source'], inplace=True)\n",
    "syn2 = pd.get_dummies(syn2)\n",
    "syn2['source'] = ['syn'] * len(syn2)\n",
    "syn2['group'] = ['train']*len(syn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4996e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.copy()\n",
    "df_new.drop(columns=['source', 'group'], inplace=True)\n",
    "df_new = pd.get_dummies(df_new)\n",
    "df_new['source'] = df['source']\n",
    "df_new['group'] = df['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fba0ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ICHLOC_Other', 'index'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_new.columns) - set(syn2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d70d80ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_cols = list(syn2.columns)\n",
    "all_cols = list(df_new.columns)\n",
    "for f in all_cols:\n",
    "    if f not in syn_cols:\n",
    "        syn2[f] = [0] * len(syn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b82b4bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = pd.concat([df_new, syn2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d8ca25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_train = merge1[(merge1['source'] == 'atach2')&(merge1['group']=='train')].copy()\n",
    "trial_train.reset_index(inplace=True, drop=True)\n",
    "df_test = merge1[merge1['group'] == 'test'].copy()\n",
    "df_train = merge1[merge1['group'] == 'train'].copy()\n",
    "syn = merge1[merge1['source'] == 'syn'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c4123c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 49)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_ids = list(obs['index'])\n",
    "matched_obs = merge1[merge1['index'].isin(matched_ids)]\n",
    "matched_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "551f6142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.855437\n"
     ]
    }
   ],
   "source": [
    "merge_temp1 = pd.concat([trial_train, matched_obs, syn])\n",
    "merge_temp1 = transform_var(merge_temp1)\n",
    "X = np.array(merge_temp1[pre_treatment_var])\n",
    "y = np.array(merge_temp1['TREATMENT'])\n",
    "pm_lgr = LogisticRegression(penalty='none', max_iter=3000)\n",
    "pm_lgr.fit(X, y)\n",
    "clip_bounds = (1e-3, 1-1e-3)\n",
    "score_lgr1 = np.clip(pm_lgr.predict_proba(X)[:, 1], *clip_bounds)\n",
    "print('AUC score: {:.6f}'.format(auc(y, score_lgr1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce63776f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 74)\n",
      "(500, 74)\n",
      "(397, 74)\n",
      "(537, 74)\n"
     ]
    }
   ],
   "source": [
    "merge_temp1['score'] = score_lgr1\n",
    "t_syn2 = merge_temp1[(merge_temp1['TREATMENT'] == 1) & (merge_temp1['source'] == 'syn')].copy()\n",
    "c_syn2 = merge_temp1[(merge_temp1['TREATMENT'] == 0) & (merge_temp1['source'] == 'syn')].copy()\n",
    "t_real = merge_temp1[(merge_temp1['TREATMENT'] == 1) & (merge_temp1['source'] != 'syn')].copy()\n",
    "c_real = merge_temp1[(merge_temp1['TREATMENT'] == 0) & (merge_temp1['source'] != 'syn')].copy()\n",
    "print(t_syn2.shape), print(c_syn2.shape), print(t_real.shape), print(c_real.shape)\n",
    "\n",
    "temp21 = pd.concat([t_syn2, c_real])\n",
    "temp21['treatment'] = 1 - temp21['TREATMENT']\n",
    "temp21.index = np.arange(0, len(temp21))\n",
    "temp22 = pd.concat([c_syn2, t_real])\n",
    "temp22.index = np.arange(0, len(temp22))\n",
    "\n",
    "# PSM21: use real control to find matched treatment\n",
    "psm21 = NearestNeighborMatch(caliper=0.2, replace=False, ratio=1, random_state=2205)\n",
    "matched_syn21 = psm21.match(data=temp21, treatment_col='treatment',score_cols=['score'])\n",
    "\n",
    "# PSM22: use real treatment to find matched control\n",
    "psm22 = NearestNeighborMatch(caliper=0.2, replace=False, ratio=1, random_state=2205)\n",
    "matched_syn22 = psm22.match(data=temp22, treatment_col='TREATMENT',score_cols=['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aebc8042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_syn1 = pd.concat([matched_syn21[matched_syn21['TREATMENT'] == 1], matched_syn22[matched_syn22['TREATMENT'] == 0]])\n",
    "len(matched_syn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b564fb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 162)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matched_syn21[matched_syn21['TREATMENT'] == 1]), len(matched_syn22[matched_syn22['TREATMENT'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e2bb57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.680308\n"
     ]
    }
   ],
   "source": [
    "merge2 = pd.concat([trial_train, matched_obs, matched_syn1])\n",
    "merge2 = transform_var(merge2)\n",
    "y = np.array(merge2['TREATMENT'])\n",
    "X = merge2[pre_treatment_var].values\n",
    "pm_lgr = LogisticRegression(penalty='none', max_iter=3000)\n",
    "pm_lgr.fit(X, y)\n",
    "clip_bounds = (1e-3, 1-1e-3)\n",
    "score_lgr = np.clip(pm_lgr.predict_proba(X)[:, 1], *clip_bounds)\n",
    "print('AUC score: {:.6f}'.format(auc(y, score_lgr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc90312d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1196, 497, 699)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merge2), len(merge2[merge2['TREATMENT'] == 1]), len(merge2[merge2['TREATMENT']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "663207fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07918913043478261"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_merge2 = create_table_one(merge2, 'TREATMENT', pre_treatment_var)\n",
    "a = 0\n",
    "b = 0\n",
    "# Calculate average smd on ERICH + ATACH2\n",
    "for i in range(len(eval_merge2['SMD'])):\n",
    "    if (eval_merge2['SMD'][i] !='') & ~(pd.isna(eval_merge2['SMD'][i])):\n",
    "        a += abs(eval_merge2['SMD'][i])\n",
    "        b += 1\n",
    "a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb5a8558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27833043478260877"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_merge2 = create_table_one(merge_temp1, 'TREATMENT', pre_treatment_var)\n",
    "a = 0\n",
    "b = 0\n",
    "# Calculate average smd on ERICH + ATACH2\n",
    "for i in range(len(eval_merge2['SMD'])):\n",
    "    if (eval_merge2['SMD'][i] !='') & ~(pd.isna(eval_merge2['SMD'][i])):\n",
    "        a += abs(eval_merge2['SMD'][i])\n",
    "        b += 1\n",
    "a/b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eefc684",
   "metadata": {},
   "source": [
    "Hyperprameter setting:\n",
    "- nreg = 5\n",
    "- max_sample_tree = 80\n",
    "- max_treatment_tree = 30\n",
    "\n",
    "for tree:\n",
    "- nreg = 5\n",
    "- max_sample_tree = 80\n",
    "- max_treatment_tree = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc4ef2e",
   "metadata": {},
   "source": [
    "# Experiments after matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4ae942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_test.copy()\n",
    "test = test_transform_var(test, merge2)\n",
    "train_X = np.array(merge2[pre_treatment_var])\n",
    "test_X = np.array(test[pre_treatment_var])\n",
    "train_treatment=(merge2['TREATMENT']!=0).astype(int).values\n",
    "test_treatment=(test['TREATMENT']!=0).astype(int).values\n",
    "y_train = (merge2['OUTCOME_mRS90']).values\n",
    "y_test = (test['OUTCOME_mRS90']).values\n",
    "y_bin_train = np.array([0] * len(y_train))\n",
    "y_bin_train[np.where(y_train <= 2)] = 1\n",
    "y_bin_test = np.array([0] * len(y_test))\n",
    "y_bin_test[np.where(y_test <= 2)] = 1\n",
    "treatment_train = ['control'] * len(train_treatment)\n",
    "for i in range(len(train_treatment)):\n",
    "    if train_treatment[i] == 1:\n",
    "        treatment_train[i] = 'treatment'\n",
    "treatment_train = np.array(treatment_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a910289c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1196, 46), (200, 46))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b04725d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0009039822604434409"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uplift_forest_customed import UpliftTreeNew\n",
    "model_tree = UpliftTreeNew(n_reg=5, min_samples_leaf = 80, min_samples_treatment = 30, random_state=100, control_name='control')\n",
    "model_tree.fit(train_X, treatment_train, y_bin_train)\n",
    "model_tree.eval_qini(test_X, y_bin_test, test_treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa1434b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctgan_tree_rules = model_tree.get_rules()\n",
    "len(ctgan_tree_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3a73e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctgan_tree_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2749a7a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed round: 0 0.07056902069799384\n",
      "Seed round: 1 0.034126669602770686\n",
      "Seed round: 2 0.07371328170835421\n",
      "Seed round: 3 0.02584400520588578\n",
      "Seed round: 4 0.05745719106742597\n",
      "Seed round: 5 0.05522481487927093\n",
      "Seed round: 6 0.046737384329793456\n",
      "Seed round: 7 0.0632918704842996\n",
      "Seed round: 8 0.05354139503481883\n",
      "Seed round: 9 0.07033968106226106\n",
      "Seed round: 10 0.0973596406928072\n",
      "Seed round: 11 0.032363778033775194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.629e-03, tolerance: 1.091e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed round: 12 0.06404794937330954\n",
      "Seed round: 13 0.09518161317977629\n",
      "Seed round: 14 0.1090626597555841\n",
      "Seed round: 15 0.03388444098526454\n",
      "Seed round: 16 0.05247523543285911\n",
      "Seed round: 17 0.05003562691571137\n",
      "Seed round: 18 0.11923502191566737\n",
      "Seed round: 19 0.05044180515043068\n",
      "Seed round: 20 0.11675782640684733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.094e-03, tolerance: 8.420e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed round: 21 0.05752363114019471\n",
      "Seed round: 22 0.07983957392055462\n",
      "Seed round: 23 0.02810610937542351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.136e-04, tolerance: 7.375e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed round: 24 0.03246314791153111\n",
      "Seed round: 25 0.03818064151828177\n",
      "Seed round: 26 0.04913325931096152\n",
      "Seed round: 27 0.05651880908074845\n",
      "Seed round: 28 0.07629832635331084\n",
      "Seed round: 29 0.05184367020012397\n"
     ]
    }
   ],
   "source": [
    "qini_max2 = -1\n",
    "res2 = {'res_tree':[], 'res_lasso':[]}\n",
    "for seed in range(0, 30):\n",
    "    \n",
    "    model_temp = CausalRuleEnsembling(\n",
    "         tree_depth = 3, \n",
    "         tree_eval_func = 'KL', \n",
    "         n_reg=5, \n",
    "         n_estimator = 100,   \n",
    "         min_samples_leaf = 80, \n",
    "         min_samples_treatment = 30, \n",
    "         model_type='rl', \n",
    "         lin_standardise=False,\n",
    "         random_state = seed)\n",
    "    model_temp.fit(train_X, treatment_train, y_bin_train, pre_treatment_var)\n",
    "    a, b = model_temp.eval_qini(test_X, y_bin_test, test_treatment)\n",
    "    \n",
    "    res2['res_tree'].append(a)\n",
    "    res2['res_lasso'].append(b)\n",
    "    print('Seed round:', seed, b)\n",
    "    if b > qini_max2:\n",
    "        qini_max2 = b\n",
    "        final_model2 = model_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f11c4e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/tvae_tree_mrs2.txt', 'w') as filehandle:\n",
    "    for listitem in res2['res_tree']:\n",
    "        filehandle.write(f'{listitem}\\n')\n",
    "        \n",
    "with open('results/tvae_ensemble_mrs2.txt', 'w') as filehandle:\n",
    "    for listitem in res2['res_lasso']:\n",
    "        filehandle.write(f'{listitem}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8880285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.060718395588974135, 0.06138660269086791)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(res2['res_tree']),np.mean(res2['res_lasso'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcbce4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.02537838086067204, 0.02519045091247927)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(res2['res_tree']),np.std(res2['res_lasso'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68b9ad95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "209\n"
     ]
    }
   ],
   "source": [
    "rules = final_model2.get_rules()\n",
    "rules = rules[(rules['type']=='rule')]\n",
    "rules_ = rules[(rules['coef'] != 0)]\n",
    "print(len(rules_))\n",
    "print(len(rules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4939fcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11485044554004102, 0.11923502191566737)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model2.eval_qini(test_X, y_bin_test, test_treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "baf1dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'final_data/final_tave_model_mrs2_500.sav'\n",
    "pickle.dump(final_model2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "917c9af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(497, 699, 1196)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(merge2['TREATMENT']), len(merge2) - sum(merge2['TREATMENT']), len(merge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3db869d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
